{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-gpu pytorch (threads)\n",
    "\n",
    "Using `DataParallel` instead of `DistributedDataParallel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Overwriting ../models/3_pytorch_distributed_threaded.py\n"
    }
   ],
   "source": [
    "%%writefile ../models/3_pytorch_distributed_threaded.py\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import PIL\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "_PascalVOCSegmentationDataset = torchvision.datasets.VOCSegmentation(\n",
    "    '/mnt/pascal_voc_segmentation/', year='2012', image_set='train', download=True,\n",
    "    transform=None, target_transform=None, transforms=None\n",
    ")\n",
    "\n",
    "# VOCSegmentation returns a raw dataset: images are non-resized and in the PIL format. To transform them\n",
    "# something suitable for input to PyTorch, we need to wrap the output in our own dataset class.\n",
    "class PascalVOCSegmentationDataset(Dataset):\n",
    "    def __init__(self, raw):\n",
    "        super().__init__()\n",
    "        self._dataset = raw\n",
    "        self.resize_img = torchvision.transforms.Resize((256, 256), interpolation=PIL.Image.BILINEAR)\n",
    "        self.resize_segmap = torchvision.transforms.Resize((256, 256), interpolation=PIL.Image.NEAREST)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, segmap = self._dataset[idx]\n",
    "        img, segmap = self.resize_img(img), self.resize_segmap(segmap)\n",
    "        img, segmap = np.array(img), np.array(segmap)\n",
    "        img, segmap = (img / 255).astype('float32'), segmap.astype('int32')\n",
    "        img = np.transpose(img, (-1, 0, 1))\n",
    "\n",
    "        # The PASCAL VOC dataset PyTorch provides labels the edges surrounding classes in 255-valued\n",
    "        # pixels in the segmentation map. However, PyTorch requires class values to be contiguous\n",
    "        # in range 0 through n_classes, so we must relabel these pixels to 21.\n",
    "        segmap[segmap == 255] = 21\n",
    "        \n",
    "        return img, segmap\n",
    "\n",
    "dataset = PascalVOCSegmentationDataset(_PascalVOCSegmentationDataset)\n",
    "# NEW\n",
    "# Multiply the base batch size by the number of GPUs available.\n",
    "dataloader = DataLoader(dataset, batch_size=8 * torch.cuda.device_count(), shuffle=False)\n",
    "\n",
    "# num_classes is 22. PASCAL VOC includes 20 classes of interest, 1 background class, and the 1\n",
    "# special border class mentioned in the previous comment. 20 + 1 + 1 = 22.\n",
    "DeepLabV3 = torchvision.models.segmentation.deeplabv3_resnet101(\n",
    "    pretrained=False, progress=True, num_classes=22, aux_loss=None\n",
    ")\n",
    "model = DeepLabV3\n",
    "\n",
    "# NEW\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "model.cuda()\n",
    "model.train()\n",
    "\n",
    "writer = SummaryWriter(f'/spell/tensorboards/model_1')\n",
    "\n",
    "# since the background class doesn't matter nearly as much as the classes of interest to the\n",
    "# overall task a more selective loss would be more appropriate, however this training script\n",
    "# is merely a benchmark so we'll just use simple cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "def train(NUM_EPOCHS):\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        losses = []\n",
    "\n",
    "        for i, (batch, segmap) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch = batch.cuda()\n",
    "            segmap = segmap.cuda()\n",
    "\n",
    "            output = model(batch)['out']\n",
    "            loss = criterion(output, segmap.type(torch.int64))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_loss = loss.item()\n",
    "            if i % 10 == 0:\n",
    "                print(\n",
    "                    f'Finished epoch {epoch}, batch {i}. Loss: {curr_loss:.3f}.'\n",
    "                )\n",
    "\n",
    "            writer.add_scalar(\n",
    "                'training loss', curr_loss, epoch * len(dataloader) + i\n",
    "            )\n",
    "            losses.append(curr_loss)\n",
    "\n",
    "        print(\n",
    "            f'Finished epoch {epoch}. '\n",
    "            f'avg loss: {np.mean(losses)}; median loss: {np.min(losses)}'\n",
    "        )\n",
    "        if not os.path.exists('/spell/checkpoints/'):\n",
    "            os.mkdir('/spell/checkpoints/')\n",
    "        torch.save(model.state_dict(), f'/spell/checkpoints/model_{epoch}.pth')\n",
    "\n",
    "train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python ../models/3_initial_model.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}